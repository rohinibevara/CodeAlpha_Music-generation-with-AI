# music_ai_all_in_one.py

import glob, pickle, numpy as np, os, shutil
from music21 import converter, instrument, note, chord, stream
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dropout, Dense, Activation
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# ----------------------------
# 1️⃣ Prepare Notes from MIDI
# ----------------------------
print("Preparing notes from MIDI files...")
notes = []

for file in glob.glob("data/processed/**/*.mid*", recursive=True):
    midi = converter.parse(file)
    parts = instrument.partitionByInstrument(midi)
    if parts:
        notes_to_parse = parts.parts[0].recurse()
    else:
        notes_to_parse = midi.flat.notes

    for element in notes_to_parse:
        if isinstance(element, note.Note):
            notes.append(str(element.pitch))
        elif isinstance(element, chord.Chord):
            notes.append('.'.join(str(n) for n in element.normalOrder))

os.makedirs("data/metadata", exist_ok=True)
with open('data/metadata/notes.pkl', 'wb') as f:
    pickle.dump(notes, f)

print(f"Collected {len(notes)} notes/chords")

# ----------------------------
# 2️⃣ Create Sequences for LSTM
# ----------------------------
print("Creating sequences for training...")
sequence_length = 100
pitchnames = sorted(set(notes))
note_to_int = {n: i for i, n in enumerate(pitchnames)}

network_input = []
network_output = []

for i in range(len(notes) - sequence_length):
    seq_in = notes[i:i+sequence_length]
    seq_out = notes[i+sequence_length]
    network_input.append([note_to_int[n] for n in seq_in])
    network_output.append(note_to_int[seq_out])

n_patterns = len(network_input)
n_vocab = len(pitchnames)

X = np.reshape(network_input, (n_patterns, sequence_length, 1)) / float(n_vocab)
y = to_categorical(network_output, num_classes=n_vocab)

print("Input shape:", X.shape)
print("Output shape:", y.shape)

# ----------------------------
# 3️⃣ Build & Train LSTM Model
# ----------------------------
print("Building LSTM model...")
model = Sequential()
model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512))
model.add(Dense(256))
model.add(Dropout(0.3))
model.add(Dense(y.shape[1], activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

print("Training model...")
model.fit(X, y, epochs=50, batch_size=64)
model.save("music_ai_model.h5")
print("Model saved!")

# ----------------------------
# 4️⃣ Generate New Music
# ----------------------------
print("Generating new music sequence...")
start = np.random.randint(0, len(notes) - sequence_length - 1)
pattern = notes[start:start+sequence_length]
output_notes = []

for _ in range(500):  # generate 500 notes
    x = np.reshape([note_to_int[n] for n in pattern], (1, sequence_length, 1)) / float(n_vocab)
    prediction = model.predict(x, verbose=0)
    index = np.argmax(prediction)
    result = pitchnames[index]
    output_notes.append(result)
    pattern.append(result)
    pattern = pattern[1:]

midi_stream = stream.Stream()
for pattern in output_notes:
    if '.' in pattern or pattern.isdigit():
        chord_notes = [note.Note(int(n)) for n in pattern.split('.')]
        midi_stream.append(chord.Chord(chord_notes))
    else:
        midi_stream.append(note.Note(pattern))

midi_stream.write('midi', fp='generated_music.mid')
print("Generated music saved as generated_music.mid")
